{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"font-family:Cursive; font-weight:bold; letter-spacing: 2px ; font-size:85%; text-align:center;padding: 10px; border-bottom: 5px solid #9447e6 ; background-color: #4abaed\">Introduction:</p>","metadata":{}},{"cell_type":"markdown","source":"![](https://th.bing.com/th/id/OIP.utjtoPkFQU8W722O9DQClQHaEn?pid=ImgDet&rs=1)","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border: 3px solid #f0ad4e; background-color: #fcf8e3; padding: 10px;\">\n    \nTime series forecasting is a powerful technique for predicting future values of a target variable based on its past values. A time series dataset typically consists of a sequence of data points collected over time, with each data point representing a <b>measurement or observation</b> at a specific point in time.\n\nTime series forecasting is different from other types of prediction problems because it involves analyzing the temporal patterns and trends in the data. This means that the order of the data points matters, and that there may be <b>seasonality, trends,residuals, and other patterns</b> that need to be accounted for in order to make accurate predictions.\n\n<b>ML</b> models can be trained to automatically detect and account for variables that affect the target variable, such as promotions and special days, and can be used to generate accurate forecasts for a wide range of time series datasets.\n\n<b>AIMs</b>\n\nWe aim to develop a flexible and scalable framework that can be applied to a wide range of time series datasets, while accounting for variables that can affect the target variable, and examining the relationship between ensemble techniques and forecasting error.\n\nBy combining the strengths of multiple ML models and techniques, we aim to achieve better forecasting performance and gain deeper insights into the underlying patterns and trends in the data.\n    </div>","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:Cursive; font-weight:bold; letter-spacing: 2px ; font-size:85%; text-align:center;padding: 10px; border-bottom: 5px solid #9447e6 ; background-color: #4abaed\">METHODOLOGY:</p>","metadata":{}},{"cell_type":"markdown","source":"<div style = 'border: 3px solid #f0ad4e; background-color: #fcf8e3; padding: 10px;'>\n<ol>\n    <li><b>Data Preprocessing</b>: The first step is to prepare the time series dataset for analysis.</li><br>\n    <li><b>Stationarity Test</b>: The next step is to test the time series for stationarity.</li><br>\n    <li><b>Determine Order of Differencing</b>: If the time series is found to be non-stationary, the next step is to determine the order of differencing required to achieve stationarity.</li><br>\n    <li><b>Identify Order of AR and MA Terms</b>: Once the time series is stationary, the next step is to identify the order of the autoregressive (AR) and moving average (MA) terms in the ARIMA model. This can be done by analyzing the autocorrelation and partial autocorrelation functions of the time series.</li><br>\n    <li><b>Fit ARIMA Model</b>: With the order of differencing, AR and MA terms identified, the next step is to fit the ARIMA model to the time series data.</li><br>\n    <li><b>Model Diagnostics</b>: After fitting the model, the next step is to evaluate its performance using diagnostic checks.</li><br>\n    <li><b>Forecasting</b>:The accuracy of the forecasts can be evaluated using measures such as Symmetric mean absolute percentage error(SMAPE).</li><br>\n    <li><b>Conclusion</b></li>\n    </ol>\n    \n</div>","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:Cursive; font-weight:bold; letter-spacing: 2px ; font-size:85%; text-align:center;padding: 10px; border-bottom: 5px solid #9447e6 ; background-color: #4abaed\">Importing Packages and Data</p>","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom prettytable import PrettyTable\nfrom colorama import Fore, Style\nimport pickle\n\nfrom sklearn.preprocessing import LabelEncoder\n\n\n#Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_percentage_error\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.metrics import mean_absolute_percentage_error","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:46.936418Z","iopub.execute_input":"2023-07-26T04:23:46.937266Z","iopub.status.idle":"2023-07-26T04:23:48.502012Z","shell.execute_reply.started":"2023-07-26T04:23:46.937228Z","shell.execute_reply":"2023-07-26T04:23:48.501009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s3e19/train.csv',index_col='id')\ntest = pd.read_csv('/kaggle/input/playground-series-s3e19/test.csv',index_col='id')\nsub = pd.read_csv('/kaggle/input/playground-series-s3e19/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:48.503787Z","iopub.execute_input":"2023-07-26T04:23:48.504113Z","iopub.status.idle":"2023-07-26T04:23:48.808621Z","shell.execute_reply.started":"2023-07-26T04:23:48.504083Z","shell.execute_reply":"2023-07-26T04:23:48.807631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:48.809876Z","iopub.execute_input":"2023-07-26T04:23:48.810211Z","iopub.status.idle":"2023-07-26T04:23:48.828229Z","shell.execute_reply.started":"2023-07-26T04:23:48.81018Z","shell.execute_reply":"2023-07-26T04:23:48.827325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the datatypes \ndata_types = train.dtypes.value_counts()\nlabels = data_types.index.astype(str)\ncounts = data_types.values.tolist()\n\n# Create the pie chart using plotly\nfig = go.Figure(data=[go.Pie(labels=labels, values=counts)])\n\n# Customize the layout of the pie chart\nfig.update_layout(\n    title='Data Types in train',\n    width=600,\n    height=450,\n    showlegend=True,\n    legend=dict(orientation=\"h\")\n)\n\n# Display the pie chart\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:48.830766Z","iopub.execute_input":"2023-07-26T04:23:48.831179Z","iopub.status.idle":"2023-07-26T04:23:49.079584Z","shell.execute_reply.started":"2023-07-26T04:23:48.831147Z","shell.execute_reply":"2023-07-26T04:23:49.07866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:49.080805Z","iopub.execute_input":"2023-07-26T04:23:49.081243Z","iopub.status.idle":"2023-07-26T04:23:49.246334Z","shell.execute_reply.started":"2023-07-26T04:23:49.08121Z","shell.execute_reply":"2023-07-26T04:23:49.245451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:49.248174Z","iopub.execute_input":"2023-07-26T04:23:49.248736Z","iopub.status.idle":"2023-07-26T04:23:49.270842Z","shell.execute_reply.started":"2023-07-26T04:23:49.248702Z","shell.execute_reply":"2023-07-26T04:23:49.269963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:49.272364Z","iopub.execute_input":"2023-07-26T04:23:49.272952Z","iopub.status.idle":"2023-07-26T04:23:49.425269Z","shell.execute_reply.started":"2023-07-26T04:23:49.27292Z","shell.execute_reply":"2023-07-26T04:23:49.424269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating pie charts for visualizing the counts\ndef create_pie_chart(data, column):\n\n    value_counts = data[column].value_counts()\n    labels = value_counts.index.astype(str)\n    counts = value_counts.values.tolist()\n\n    fig = go.Figure(data=[go.Pie(labels=labels, values=counts)])\n\n    fig.update_layout(\n        title=f'Counts of {column}',\n        width=600,\n        height=450,\n        showlegend=True,\n        legend=dict(orientation=\"h\")\n    )\n\n    fig.show()\n\n# Create a pie chart for country\ncreate_pie_chart(train, 'country')\n\n# Create a pie chart for store\ncreate_pie_chart(train, 'store')\n\n# Create a pie chart for product\ncreate_pie_chart(train, 'product')","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:49.42677Z","iopub.execute_input":"2023-07-26T04:23:49.427186Z","iopub.status.idle":"2023-07-26T04:23:49.501663Z","shell.execute_reply.started":"2023-07-26T04:23:49.427152Z","shell.execute_reply":"2023-07-26T04:23:49.500751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_feature_counts(data, feature):\n    \n    feature_counts = data[feature].value_counts().reset_index()\n    feature_counts.columns = [feature, 'Count']\n    \n    # Apply colors to the table\n    feature_counts['Color'] = feature_counts.apply(lambda row: Fore.GREEN if row['Count'] > 100 else Fore.RED, axis=1)\n    \n    # Create the pretty table\n    table = PrettyTable()\n    table.field_names = [feature, 'Count']\n    for _, row in feature_counts.iterrows():\n        color = row['Color']\n        feature_value = row[feature]\n        count = row['Count']\n        table.add_row([f'{color}{feature_value}{Style.RESET_ALL}', count])\n    \n    return str(table)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:49.503105Z","iopub.execute_input":"2023-07-26T04:23:49.503748Z","iopub.status.idle":"2023-07-26T04:23:49.511415Z","shell.execute_reply.started":"2023-07-26T04:23:49.503717Z","shell.execute_reply":"2023-07-26T04:23:49.510396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the count of each country\ncountry_counts_table = calculate_feature_counts(train, 'country')\nprint(\"Count of each country:\")\nprint(country_counts_table)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:49.517881Z","iopub.execute_input":"2023-07-26T04:23:49.518138Z","iopub.status.idle":"2023-07-26T04:23:49.544281Z","shell.execute_reply.started":"2023-07-26T04:23:49.518115Z","shell.execute_reply":"2023-07-26T04:23:49.54342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the count of each store\nstore_counts_table = calculate_feature_counts(train, 'store')\nprint(\"Count of each store:\")\nprint(store_counts_table)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:49.545317Z","iopub.execute_input":"2023-07-26T04:23:49.545612Z","iopub.status.idle":"2023-07-26T04:23:49.571918Z","shell.execute_reply.started":"2023-07-26T04:23:49.545581Z","shell.execute_reply":"2023-07-26T04:23:49.570874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the count of each product\nproduct_counts_table = calculate_feature_counts(train, 'product')\nprint(\"Count of each product:\")\nprint(product_counts_table)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:49.573765Z","iopub.execute_input":"2023-07-26T04:23:49.574653Z","iopub.status.idle":"2023-07-26T04:23:49.598592Z","shell.execute_reply.started":"2023-07-26T04:23:49.574612Z","shell.execute_reply":"2023-07-26T04:23:49.597692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_pie_chart(ax, labels, counts, title):\n\n    ax.pie(counts, labels=labels, autopct='%1.1f%%')\n    ax.set_title(title)\n\n\n# Create subplots\nfig, axes = plt.subplots(2, 2, figsize=(12, 12))\nfig.suptitle('Distribution of Products Sold')\n\n# 1) Histogram for countries\nax1 = axes[0, 0]\ncountry_counts = train['country'].value_counts()\nax1.bar(country_counts.index, country_counts)\nax1.set_xlabel('Country')\nax1.set_ylabel('Count')\nax1.set_title('Distribution of Products Sold by Country')\n\n# 2) Pie chart for countries\nax2 = axes[0, 1]\ncreate_pie_chart(ax2, country_counts.index, country_counts, 'Distribution of Products Sold by Country')\n\n# 3) Histogram for stores\nax3 = axes[1, 0]\nstore_counts = train['store'].value_counts()\nax3.bar(store_counts.index, store_counts)\nax3.set_xlabel('Store')\nax3.set_ylabel('Count')\nax3.set_title('Distribution of Products Sold by Store')\n\n# 4) Pie chart for stores\nax4 = axes[1, 1]\ncreate_pie_chart(ax4, store_counts.index, store_counts, 'Distribution of Products Sold by Store')\n\n# Adjust spacing between subplots\nplt.tight_layout()\n\n# Display the subplots\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:49.600075Z","iopub.execute_input":"2023-07-26T04:23:49.600403Z","iopub.status.idle":"2023-07-26T04:23:50.36684Z","shell.execute_reply.started":"2023-07-26T04:23:49.600372Z","shell.execute_reply":"2023-07-26T04:23:50.365942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the 'date' column to datetime format\n\ntrain['date'] = pd.to_datetime(train['date'])\n\n# Set the 'date' column as the index\ntrain.set_index('date', inplace=True)\n\n\ntest['date'] = pd.to_datetime(test['date'])\n\n# Set the 'date' column as the index\ntest.set_index('date', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:50.36782Z","iopub.execute_input":"2023-07-26T04:23:50.368148Z","iopub.status.idle":"2023-07-26T04:23:50.408921Z","shell.execute_reply.started":"2023-07-26T04:23:50.368116Z","shell.execute_reply":"2023-07-26T04:23:50.408059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate the total trend for num_sold over time\nplt.figure(figsize=(12, 6))\ntrain['num_sold'].resample('M').sum().plot()\nplt.title('Total trend of num_sold over time')\nplt.xlabel('Date')\nplt.ylabel('Total num_sold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:50.410204Z","iopub.execute_input":"2023-07-26T04:23:50.410752Z","iopub.status.idle":"2023-07-26T04:23:50.743277Z","shell.execute_reply.started":"2023-07-26T04:23:50.410719Z","shell.execute_reply":"2023-07-26T04:23:50.742383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\" style=\"border: 3px solid #f0ad4e; background-color: #fcf8e3; padding: 10px;\">\n    <font color = 'black'>\nüëâTotal trend for the num_sold over time: This plot shows the total number of products sold over time, aggregated by month,as we can clearly see that the number of sold has decreased after every 1st month of every year and in the year 2020, and increased rapidly at the end of every year </font>","metadata":{}},{"cell_type":"code","source":"# Country with the highest num_sold based on the year\ncountry_num_sold = train.groupby([train.index.year, 'country'])['num_sold'].sum()\ncountry_num_sold = country_num_sold.unstack()\ncountry_num_sold.plot(kind='bar', figsize=(12, 6))\nplt.title('Total num_sold by Country (Yearly)')\nplt.xlabel('Year')\nplt.ylabel('Total num_sold')\nplt.legend(title='Country')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:50.744654Z","iopub.execute_input":"2023-07-26T04:23:50.745641Z","iopub.status.idle":"2023-07-26T04:23:51.150316Z","shell.execute_reply.started":"2023-07-26T04:23:50.745606Z","shell.execute_reply":"2023-07-26T04:23:51.14941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\" style=\"border: 3px solid #f0ad4e; background-color: #fcf8e3; padding: 10px;\">\n    <font color = 'black'>\nüëâCountry with the highest num_sold based on the year: This bar chart displays the total number of products sold by country, grouped by year, as we can clearly say from this plot Canada has more sales in every year followed by Japan,The least one is Argentina</font>\n","metadata":{}},{"cell_type":"code","source":"# Store with the highest sales based on the year\nstore_num_sold = train.groupby([train.index.year, 'store'])['num_sold'].sum()\nstore_num_sold = store_num_sold.unstack()\nstore_num_sold.plot(kind='bar', figsize=(12, 6))\nplt.title('Total num_sold by Store (Yearly)')\nplt.xlabel('Year')\nplt.ylabel('Total num_sold')\nplt.legend(title='Store')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:23:51.152289Z","iopub.execute_input":"2023-07-26T04:23:51.153046Z","iopub.status.idle":"2023-07-26T04:23:51.51404Z","shell.execute_reply.started":"2023-07-26T04:23:51.153013Z","shell.execute_reply":"2023-07-26T04:23:51.5131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\" style=\"border: 3px solid #f0ad4e; background-color: #fcf8e3; padding: 10px;\">\n    <font color = 'black'>\nüëâStore with the highest sales based on the year: This bar chart displays the total number of products sold by store, grouped by year, Kagglazon tops the chart, least one is kaggle learn</font>","metadata":{}},{"cell_type":"code","source":"# Country-wise sales based on product:\nplt.figure(figsize = (12,6))\nsns.barplot(train,x='country',y='num_sold',hue='product')\nplt.xlabel('Country')\nplt.ylabel('No. of products sold')\nplt.title('country-wise sales analysis based on product')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:28:03.804147Z","iopub.execute_input":"2023-07-26T04:28:03.804745Z","iopub.status.idle":"2023-07-26T04:28:07.07532Z","shell.execute_reply.started":"2023-07-26T04:28:03.804701Z","shell.execute_reply":"2023-07-26T04:28:07.074397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Product with the highest num_sold based on the year\nproduct_num_sold = train.groupby([train.index.year, 'product'])['num_sold'].sum()\nproduct_num_sold = product_num_sold.unstack()\nproduct_num_sold.plot(kind='bar', figsize=(12, 6))\nplt.title('Total num_sold by Product (Yearly)')\nplt.xlabel('Year')\nplt.ylabel('Total num_sold')\nplt.legend(title='Product')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:28:12.324673Z","iopub.execute_input":"2023-07-26T04:28:12.325034Z","iopub.status.idle":"2023-07-26T04:28:12.731834Z","shell.execute_reply.started":"2023-07-26T04:28:12.325005Z","shell.execute_reply":"2023-07-26T04:28:12.730897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\" style=\"border: 3px solid #f0ad4e; background-color: #fcf8e3; padding: 10px;\">\n    <font color = 'black'>\nüëâProduct with the highest num_sold based on the year: This bar chart displays the total number of products sold by product, grouped by year, as we can see from the above plot there is a stiff competition between the Using LLMS to improve your coding and to train more LLMS </font>","metadata":{}},{"cell_type":"code","source":"%%time\n# Plot the trend for each country\nsns.lineplot(data=train, x='date', y='num_sold', hue='country')\n\n# Customize the plot\nplt.xlabel('Date')\nplt.ylabel('Number of Products Sold')\nplt.title('Trend of Products Sold by Country')\nplt.legend(title='Country')\n\n# Adjust the plot layout\n# we adjust the plot layout using plt.tight_layout() to ensure that all components fit properly\nplt.tight_layout()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:28:22.829951Z","iopub.execute_input":"2023-07-26T04:28:22.830306Z","iopub.status.idle":"2023-07-26T04:32:48.482505Z","shell.execute_reply.started":"2023-07-26T04:28:22.830277Z","shell.execute_reply":"2023-07-26T04:32:48.481657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the occurrences where num_sold is 0\nnum_zero_sold = (train['num_sold'] == 0).sum()\n\nprint(f\"Number of occurrences where num_sold is 0: {num_zero_sold}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:32:57.149414Z","iopub.execute_input":"2023-07-26T04:32:57.150512Z","iopub.status.idle":"2023-07-26T04:32:57.158357Z","shell.execute_reply.started":"2023-07-26T04:32:57.150452Z","shell.execute_reply":"2023-07-26T04:32:57.157325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id = 'h4' class = 'alert alert-block alert-info' style=\"border-bottom: 5px solid #9370db; background-color: #f0f8ff; padding: 10px;\">\n    <h2>Stationarity testing and Determine Order of Differencing</h2>\n    </div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\" style=\"border: 3px solid #f0ad4e; background-color: #fcf8e3; padding: 10px;\">\n    <font color = 'black'>\nüëâ**Testing the stationarity of a time series using the Augmented Dickey-Fuller (ADF) test from the statsmodels library:**</font>\n","metadata":{}},{"cell_type":"code","source":"# define the time series as a pandas Series\nts = train['num_sold']","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:33:03.266346Z","iopub.execute_input":"2023-07-26T04:33:03.267033Z","iopub.status.idle":"2023-07-26T04:33:03.27177Z","shell.execute_reply.started":"2023-07-26T04:33:03.267001Z","shell.execute_reply":"2023-07-26T04:33:03.27058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\nresult = adfuller(ts)\n\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t%s: %.3f' % (key, value))","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:33:04.301459Z","iopub.execute_input":"2023-07-26T04:33:04.302191Z","iopub.status.idle":"2023-07-26T04:33:54.314573Z","shell.execute_reply.started":"2023-07-26T04:33:04.302159Z","shell.execute_reply":"2023-07-26T04:33:54.311404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family:Cursive; font-weight:bold; letter-spacing: 2px; color:black; background-color:#4abaed ; font-size:85%; text-align:center;padding: 10px; border-bottom: 5px solid #9447e6\">ARIMA:</p>\n<br>\n<div style=\"border-radius:10px;border:#FFF722 solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n<b><h1><span style='color:#85BB65'>|</span> Detail Explanation Of Stationary and Non Stationary data</h1></b> <br>\n    <ol>\n        <li><b>Stationary  :</b> A Time series is said to be <span style = 'background-color: #FFF722; color : black'><b>stationary</b></span> when its statistical properties, such as <span style = 'color : #85BB65'><b> mean, variance, and autocorrelation, remain constant over time</b></span>. To check for stationarity, you can visually inspect the time series plot or use statistical tests like the <span style = 'background-color:#F0AAE3'><b>Augmented Dickey-Fuller (ADF) test</b></span>. If the <span style = 'background-color:#F0E4D5'><b>p-value </b></span> obtained from the ADF test is less than a chosen significance level (e.g., 0.05), then you can reject the null hypothesis and conclude that the series is stationary</li><br>\n        <li><b>Non stationary :</b> A non stationary time series exhibits a <span style = 'color:#4244F0'><b>trend, seasonality, or both, </b></span> which causes its statistical properties to change over time. In such cases, traditional time series models like ARIMA cannot be applied directly. Common reasons for non-stationarity include trends <span style = 'background-color:#F0E4D5'><b>(upward or downward movement over time) and seasonality (regular patterns that repeat at fixed intervals).</b></span>.</li>\n    </ol>","metadata":{}},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:33:54.321027Z","iopub.execute_input":"2023-07-26T04:33:54.322282Z","iopub.status.idle":"2023-07-26T04:33:54.344359Z","shell.execute_reply.started":"2023-07-26T04:33:54.322223Z","shell.execute_reply":"2023-07-26T04:33:54.343101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf\nplot_acf(train['num_sold'], alpha = 0.05);","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:33:54.346097Z","iopub.execute_input":"2023-07-26T04:33:54.346781Z","iopub.status.idle":"2023-07-26T04:34:00.478416Z","shell.execute_reply.started":"2023-07-26T04:33:54.346748Z","shell.execute_reply":"2023-07-26T04:34:00.477407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id = 'h4' class = 'alert alert-block alert-info' style=\"border-bottom: 5px solid #9370db; background-color: #f0f8ff; padding: 10px;\">\n    <h1>Model Building</h1>\n    </div>","metadata":{}},{"cell_type":"markdown","source":"<div  class = 'alert alert-block alert-info' style=\"border-bottom: 5px solid #9370db; background-color: #f0f8ff; padding: 10px;\">\n    <h3>Random Forest Regressor</h3> \n</div>","metadata":{}},{"cell_type":"code","source":"# Create a label encoder\nlabel_encoder = LabelEncoder()\n\n# Encode categorical variables\ntrain['country'] = label_encoder.fit_transform(train['country'])\ntrain['store'] = label_encoder.fit_transform(train['store'])\ntrain['product'] = label_encoder.fit_transform(train['product'])\n\n# Step 2: Split the data into train and validation sets\ntrain_size = int(0.8 * len(train))\ntrain_data = train[:train_size]\nvalidation_data = train[train_size:]\n\n\n# Random Forests\nrf_model = RandomForestRegressor(n_estimators=100, random_state=0)\nrf_model.fit(train_data.drop('num_sold', axis=1), train_data['num_sold'])\nrf_forecast = rf_model.predict(validation_data.drop('num_sold', axis=1))\n\n# Gradient Boosting\ngb_model = GradientBoostingRegressor(n_estimators=100, random_state=0)\ngb_model.fit(train_data.drop('num_sold', axis=1), train_data['num_sold'])\ngb_forecast = gb_model.predict(validation_data.drop('num_sold', axis=1))\n\n# Step 4: Evaluate the forecasts using MAPE\nrf_mape = mean_absolute_percentage_error(validation_data['num_sold'], rf_forecast)\ngb_mape = mean_absolute_percentage_error(validation_data['num_sold'], gb_forecast)\n\nprint(f\"Random Forests MAPE: {rf_mape}\")\nprint(f\"Gradient Boosting MAPE: {gb_mape}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:34:15.484434Z","iopub.execute_input":"2023-07-26T04:34:15.484923Z","iopub.status.idle":"2023-07-26T04:34:19.73149Z","shell.execute_reply.started":"2023-07-26T04:34:15.484881Z","shell.execute_reply":"2023-07-26T04:34:19.730348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Additional step: Visualize the actual vs. predicted values for the validation data\nplt.plot(validation_data.index, validation_data['num_sold'], label='Actual')\nplt.plot(validation_data.index, rf_forecast, label='Random Forests Forecast')\nplt.plot(validation_data.index, gb_forecast, label='Gradient Boosting Forecast')\nplt.xlabel('Date')\nplt.ylabel('num_sold')\nplt.title('Actual vs. Forecasted num_sold (Validation Data)')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:34:26.116878Z","iopub.execute_input":"2023-07-26T04:34:26.117241Z","iopub.status.idle":"2023-07-26T04:34:26.605719Z","shell.execute_reply.started":"2023-07-26T04:34:26.117212Z","shell.execute_reply":"2023-07-26T04:34:26.604797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:34:29.179113Z","iopub.execute_input":"2023-07-26T04:34:29.179487Z","iopub.status.idle":"2023-07-26T04:34:29.192193Z","shell.execute_reply.started":"2023-07-26T04:34:29.179444Z","shell.execute_reply":"2023-07-26T04:34:29.191267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 2: Encode categorical variables\ntest['country'] = label_encoder.fit_transform(test['country'])\ntest['store'] = label_encoder.fit_transform(test['store'])\ntest['product'] = label_encoder.fit_transform(test['product'])\n\n# Step 3: Apply the trained Random Forest model to predictions\ntest_predictions = rf_model.predict(test)\ntest_predictions_gb = gb_model.predict(test)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:34:32.895123Z","iopub.execute_input":"2023-07-26T04:34:32.895492Z","iopub.status.idle":"2023-07-26T04:34:33.003171Z","shell.execute_reply.started":"2023-07-26T04:34:32.895447Z","shell.execute_reply":"2023-07-26T04:34:33.002239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['num_sold']=test_predictions\nsub","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:34:36.472599Z","iopub.execute_input":"2023-07-26T04:34:36.473004Z","iopub.status.idle":"2023-07-26T04:34:36.4917Z","shell.execute_reply.started":"2023-07-26T04:34:36.472971Z","shell.execute_reply":"2023-07-26T04:34:36.490525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission_rf(12-07-23).csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:34:42.173642Z","iopub.execute_input":"2023-07-26T04:34:42.173998Z","iopub.status.idle":"2023-07-26T04:34:42.297529Z","shell.execute_reply.started":"2023-07-26T04:34:42.17397Z","shell.execute_reply":"2023-07-26T04:34:42.296427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save the model in pickle\npickle.dump(rf_model, open('/kaggle/working/SalesForecasting_pickle_file(RF)', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-07-26T04:35:18.079415Z","iopub.execute_input":"2023-07-26T04:35:18.080117Z","iopub.status.idle":"2023-07-26T04:35:18.09119Z","shell.execute_reply.started":"2023-07-26T04:35:18.080083Z","shell.execute_reply":"2023-07-26T04:35:18.090305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\" style=\"border: 3px solid #f0ad4e; background-color: #fcf8e3; padding: 10px;\">\n    <h4> Conclusion:</h4>\n    <font color = 'black'>\nüëâToday, my main focus was on the analysis part of the data. I have explored the dataset, visualized trends, calculated counts, and worked on predictive modeling using base line Random Forests regressor. However, I plan to further enhance the forecasting aspect of the project by implementing the ARIMA model tomorrow.</font>\n                      <h2>If you appreciate my work, please consider upvoting it üëç</h2>\n    </div>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}